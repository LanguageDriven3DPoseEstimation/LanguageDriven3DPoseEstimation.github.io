<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <!-- <title>Language-driven 3D Pose Estimation</title> -->
    <style>
        /* body {
            display: flex;
            text-align: center;
            background-color: #f0f0f0; 
        }*/
        .content {
            text-align: center;
            background-color: #fff; 
        }
        h1 {
            font-size: 3em;
        }
        h2{
            font-size: 2em;
        }
        a {
            display: inline-block;
            margin-top: 1em;
            padding: 0.5em 1em;
            background-color: #000; /* 黑色背景 */
            color: #fff; /* 白色文字 */
            text-decoration: none;
            border-radius: 50px; /* 边框圆角，形成椭圆效果 */
            font-size: 1.3em; /* 增大字体大小 */
        }

        .image {
            width: 1000;
            height: auto; /* 保持宽高比 */
            display: block;
            margin: 0 auto; /* 居中 */
        } 
        .dataset_sample {
            padding-top: 20px; /* 上部空白 */
            /* 你可以根据需要调整上面的数值 */
        }
        /* h4 {
            font-size: 1.2em;
            margin-bottom: 1em;
            color: #555;
        }
        a {
            display: inline-block;
            margin-top: 1em;
            padding: 0.5em 1em;
            background-color: #007bff;
            color: #fff;
            text-decoration: none;
            border-radius: 4px;
        }
        a:hover {
            background-color: #0056b3;
        }   */
    </style>
</head>
<body>
    <div class="content">
        <h1>Language-driven 3D Pose Estimation: Grounding Motion from Text Descriptions</h1>
        <h3>Anonymous author</h4>
        <a href="https://languagedriven3dposeestimation.github.io/">Paper</a>
        <a href="https://drive.google.com/drive/folders/1j5ScZHHn6s7LFRbQJB71g-J80Xmuj_MM?usp=sharing">Dataset</a> 
        <a href="https://languagedriven3dposeestimation.github.io/">Code</a> 
    </div>
    <div class="dataset_sample">
        <img src="g_1.gif" class="image">
        <img src="g_2.gif" class="image">
    </div>
    <div class="content">
        <h2>Abstract</h2>
        In an NBA game scenario, consider the challenge of locating and analyzing the 3D poses of players performing a user-specified action, such as attempting a shot. Traditional 3D human pose estimation (3DHPE) methods often fall short in such complex, multi-person scenes due to their lack of semantic integration and reliance on isolated pose data. To address these limitations, we introduce Language-Driven 3D Human Pose Estimation (L3DHPE), a novel approach that extends 3DHPE to general multi-person contexts by incorporating detailed language descriptions. We present Panoptic-L3D, the first dataset designed for L3DHPE, featuring over 3,800 linguistic annotations for more than 1,400 individuals across over 500 videos, with frame-level 3D skeleton annotations. Additionally, we propose Cascaded Pose Perception (CPP), a benchmarking method that simultaneously performs language-driven mask segmentation and 3D pose estimation within a unified model. CPP first learns 2D pose information, utilizes a body fusion module to aid in mask segmentation, and employs a mask fusion module to mitigate mask noise before outputting 3D poses. Our extensive evaluation of CPP and existing benchmarks on the Panoptic-L3D dataset demonstrates the necessity of this novel task and dataset for advancing 3DHPE.
    </div>

    <p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><a property="dct:title" rel="cc:attributionURL" href="https://languagedriven3dposeestimation.github.io/">Language-driven 3D Pose Estimation: Grounding Motion from Text Descriptions</a> by <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://languagedriven3dposeestimation.github.io/">Anonymous author</a> is licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-NC-SA 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1" alt=""></a></p>

</body>
</html>